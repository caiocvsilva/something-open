2023/11/30 13:57:34 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
    CUDA available: True
    numpy_random_seed: 545567379
    GPU 0,1: NVIDIA TITAN V
    GPU 2,3: NVIDIA GeForce GTX TITAN X
    CUDA_HOME: /apps/cuda/cuda-11.4
    NVCC: Cuda compilation tools, release 11.4, V11.4.48
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 2.1.0+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.0
    OpenCV: 4.8.1
    MMEngine: 0.9.1

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 545567379
    diff_rank_seed: False
    deterministic: False
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 4
------------------------------------------------------------

2023/11/30 13:57:34 - mmengine - INFO - Config:
ann_file_test = '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_test.txt'
ann_file_train = '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_train.txt'
ann_file_val = '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_val.txt'
auto_scale_lr = dict(base_batch_size=8, enable=False)
base_lr = 0.0016
data_root = ''
data_root_val = ''
dataset_type = 'VideoDataset'
default_hooks = dict(
    checkpoint=dict(
        interval=1, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),
    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    runtime_info=dict(type='RuntimeInfoHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffers=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmaction'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
file_client_args = dict(io_backend='disk')
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)
model = dict(
    backbone=dict(arch='small', drop_path_rate=0.2, type='MViT'),
    cls_head=dict(
        average_clips='prob',
        in_channels=768,
        label_smooth_eps=0.1,
        num_classes=26339,
        type='MViTHead'),
    data_preprocessor=dict(
        blending=dict(
            augments=[
                dict(alpha=0.8, num_classes=26339, type='MixupBlending'),
                dict(alpha=1, num_classes=26339, type='CutmixBlending'),
            ],
            type='RandomBatchAugment'),
        format_shape='NCTHW',
        mean=[
            114.75,
            114.75,
            114.75,
        ],
        std=[
            57.375,
            57.375,
            57.375,
        ],
        type='ActionDataPreprocessor'),
    type='Recognizer3D')
optim_wrapper = dict(
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0016, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0))
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=30,
        start_factor=0.1,
        type='LinearLR'),
    dict(
        T_max=100,
        begin=30,
        by_epoch=True,
        convert_to_iter_based=True,
        end=100,
        eta_min=1.6e-05,
        type='CosineAnnealingLR'),
]
randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_test.txt',
        data_prefix=dict(video=''),
        pipeline=[
            dict(io_backend='disk', type='DecordInit'),
            dict(clip_len=16, test_mode=True, type='UniformSample'),
            dict(type='DecordDecode'),
            dict(scale=(
                -1,
                224,
            ), type='Resize'),
            dict(crop_size=224, type='ThreeCrop'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        test_mode=True,
        type='VideoDataset'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='AccMetric')
test_pipeline = [
    dict(io_backend='disk', type='DecordInit'),
    dict(clip_len=16, test_mode=True, type='UniformSample'),
    dict(type='DecordDecode'),
    dict(scale=(
        -1,
        224,
    ), type='Resize'),
    dict(crop_size=224, type='ThreeCrop'),
    dict(input_format='NCTHW', type='FormatShape'),
    dict(type='PackActionInputs'),
]
train_cfg = dict(
    max_epochs=20, type='EpochBasedTrainLoop', val_begin=3, val_interval=3)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_train.txt',
        data_prefix=dict(video=''),
        pipeline=[
            dict(io_backend='disk', type='DecordInit'),
            dict(clip_len=16, type='UniformSample'),
            dict(type='DecordDecode'),
            dict(scale=(
                -1,
                256,
            ), type='Resize'),
            dict(type='RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                224,
                224,
            ), type='Resize'),
            dict(
                magnitude=7,
                num_layers=4,
                op='RandAugment',
                type='PytorchVideoWrapper'),
            dict(erase_prob=0.25, mode='rand', type='RandomErasing'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        type='VideoDataset'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(io_backend='disk', type='DecordInit'),
    dict(clip_len=16, type='UniformSample'),
    dict(type='DecordDecode'),
    dict(scale=(
        -1,
        256,
    ), type='Resize'),
    dict(type='RandomResizedCrop'),
    dict(keep_ratio=False, scale=(
        224,
        224,
    ), type='Resize'),
    dict(
        magnitude=7,
        num_layers=4,
        op='RandAugment',
        type='PytorchVideoWrapper'),
    dict(erase_prob=0.25, mode='rand', type='RandomErasing'),
    dict(input_format='NCTHW', type='FormatShape'),
    dict(type='PackActionInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        '/home/c/caiodasilva/something-open/gaivi_video_ann_knuv_val.txt',
        data_prefix=dict(video=''),
        pipeline=[
            dict(io_backend='disk', type='DecordInit'),
            dict(clip_len=16, test_mode=True, type='UniformSample'),
            dict(type='DecordDecode'),
            dict(scale=(
                -1,
                256,
            ), type='Resize'),
            dict(crop_size=224, type='CenterCrop'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        test_mode=True,
        type='VideoDataset'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='AccMetric')
val_pipeline = [
    dict(io_backend='disk', type='DecordInit'),
    dict(clip_len=16, test_mode=True, type='UniformSample'),
    dict(type='DecordDecode'),
    dict(scale=(
        -1,
        256,
    ), type='Resize'),
    dict(crop_size=224, type='CenterCrop'),
    dict(input_format='NCTHW', type='FormatShape'),
    dict(type='PackActionInputs'),
]
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='ActionVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/something_knuv_100'

2023/11/30 13:57:37 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.0.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.1.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.2.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.3.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.4.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.5.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.6.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.7.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.8.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.9.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.10.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.11.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.12.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.13.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.14.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.norm1.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.norm1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.qkv.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.proj.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_q.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_q.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_k.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_k.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_v.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.attn.norm_v.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.norm2.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.norm2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.mlp.fc1.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.blocks.15.mlp.fc2.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2023/11/30 13:57:38 - mmengine - INFO - paramwise_options -- cls_head.fc_cls.bias:weight_decay=0.0
Name of parameter - Initialization information

backbone.cls_token - torch.Size([1, 1, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.patch_embed.projection.weight - torch.Size([96, 3, 3, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.patch_embed.projection.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.0.norm1.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.0.attn.rel_pos_h - torch.Size([111, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.0.attn.rel_pos_w - torch.Size([111, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.0.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.0.attn.qkv.weight - torch.Size([288, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.attn.qkv.bias - torch.Size([288]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.attn.proj.weight - torch.Size([96, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.attn.proj.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.0.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.0.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.0.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.0.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.0.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.0.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.0.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.0.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.0.norm2.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.0.mlp.fc1.weight - torch.Size([384, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.mlp.fc1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.mlp.fc2.weight - torch.Size([96, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.0.mlp.fc2.bias - torch.Size([96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.1.norm1.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.1.attn.rel_pos_h - torch.Size([55, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.1.attn.rel_pos_w - torch.Size([55, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.1.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.1.attn.qkv.weight - torch.Size([576, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.attn.qkv.bias - torch.Size([576]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.attn.proj.weight - torch.Size([192, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.attn.proj.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.1.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.1.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.1.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.1.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.1.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.1.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.1.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.1.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.1.norm2.bias - torch.Size([192]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.1.mlp.fc1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.mlp.fc1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.mlp.fc2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.mlp.fc2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.proj.weight - torch.Size([192, 96]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.1.proj.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.2.norm1.bias - torch.Size([192]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.2.attn.rel_pos_h - torch.Size([55, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.2.attn.rel_pos_w - torch.Size([55, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.2.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.2.attn.qkv.weight - torch.Size([576, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.attn.qkv.bias - torch.Size([576]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.attn.proj.weight - torch.Size([192, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.attn.proj.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.2.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.2.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.2.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.2.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.2.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.2.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.2.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.2.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.2.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.2.norm2.bias - torch.Size([192]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.2.mlp.fc1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.mlp.fc1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.mlp.fc2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.2.mlp.fc2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.3.norm1.bias - torch.Size([192]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.3.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.3.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.3.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.3.attn.qkv.weight - torch.Size([1152, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.3.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.3.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.3.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.3.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.3.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.3.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.3.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.3.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.3.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.3.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.proj.weight - torch.Size([384, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.3.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.4.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.4.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.4.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.4.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.4.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.4.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.4.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.4.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.4.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.4.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.4.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.4.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.4.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.4.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.4.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.4.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.5.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.5.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.5.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.5.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.5.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.5.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.5.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.5.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.5.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.5.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.5.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.5.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.5.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.5.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.5.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.5.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.6.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.6.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.6.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.6.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.6.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.6.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.6.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.6.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.6.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.6.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.6.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.6.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.6.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.6.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.6.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.6.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.6.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.7.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.7.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.7.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.7.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.7.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.7.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.7.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.7.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.7.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.7.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.7.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.7.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.7.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.7.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.7.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.7.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.7.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.8.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.8.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.8.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.8.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.8.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.8.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.8.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.8.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.8.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.8.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.8.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.8.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.8.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.8.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.8.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.8.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.8.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.9.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.9.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.9.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.9.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.9.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.9.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.9.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.9.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.9.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.9.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.9.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.9.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.9.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.9.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.9.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.9.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.9.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.10.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.10.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.10.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.10.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.10.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.10.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.10.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.10.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.10.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.10.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.10.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.10.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.10.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.10.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.10.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.10.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.10.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.11.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.11.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.11.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.11.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.11.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.11.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.11.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.11.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.11.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.11.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.11.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.11.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.11.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.11.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.11.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.11.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.11.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.12.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.12.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.12.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.12.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.12.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.12.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.12.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.12.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.12.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.12.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.12.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.12.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.12.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.12.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.12.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.12.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.12.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.13.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.13.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.13.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.13.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.13.attn.qkv.weight - torch.Size([1152, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.attn.qkv.bias - torch.Size([1152]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.attn.proj.weight - torch.Size([384, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.attn.proj.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.13.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.13.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.13.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.13.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.13.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.13.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.13.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.13.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.13.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.13.norm2.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.13.mlp.fc1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.mlp.fc1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.mlp.fc2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.13.mlp.fc2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.14.norm1.bias - torch.Size([384]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.14.attn.rel_pos_h - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.14.attn.rel_pos_w - torch.Size([27, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.14.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.14.attn.qkv.weight - torch.Size([2304, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.attn.qkv.bias - torch.Size([2304]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.attn.proj.weight - torch.Size([768, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.attn.proj.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.14.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.14.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.14.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.14.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.14.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.14.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.14.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.14.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.14.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.14.norm2.bias - torch.Size([768]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.14.mlp.fc1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.mlp.fc1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.mlp.fc2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.mlp.fc2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.proj.weight - torch.Size([768, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.14.proj.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.15.norm1.bias - torch.Size([768]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.15.attn.rel_pos_h - torch.Size([13, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.15.attn.rel_pos_w - torch.Size([13, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.15.attn.rel_pos_t - torch.Size([15, 96]): 
Initialized by user-defined `init_weights` in MultiScaleAttention  

backbone.blocks.15.attn.qkv.weight - torch.Size([2304, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.attn.qkv.bias - torch.Size([2304]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.attn.proj.weight - torch.Size([768, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.attn.proj.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.attn.pool_q.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.15.attn.norm_q.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.15.attn.norm_q.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.15.attn.pool_k.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.15.attn.norm_k.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.15.attn.norm_k.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.15.attn.pool_v.weight - torch.Size([96, 1, 3, 3, 3]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0 

backbone.blocks.15.attn.norm_v.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.15.attn.norm_v.bias - torch.Size([96]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.15.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.blocks.15.norm2.bias - torch.Size([768]): 
ConstantInit: val=1.0, bias=0.02 

backbone.blocks.15.mlp.fc1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.mlp.fc1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.mlp.fc2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.blocks.15.mlp.fc2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.02 

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.norm3.bias - torch.Size([768]): 
ConstantInit: val=1.0, bias=0.02 

cls_head.fc_cls.weight - torch.Size([26339, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

cls_head.fc_cls.bias - torch.Size([26339]): 
The value is the same before and after calling `init_weights` of Recognizer3D  
2023/11/30 13:57:39 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/11/30 13:57:39 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/11/30 13:57:39 - mmengine - INFO - Checkpoints will be saved to /home/c/caiodasilva/mmaction2/work_dirs/something_knuv_100.
2023/11/30 13:59:59 - mmengine - INFO - Epoch(train)  [1][100/532]  base_lr: 1.6893e-04 lr: 1.6893e-04  eta: 4:07:17  time: 1.3483  data_time: 0.0110  memory: 6878  loss: 6.4268  loss_cls: 6.4268
2023/11/30 14:02:14 - mmengine - INFO - Epoch(train)  [1][200/532]  base_lr: 1.7796e-04 lr: 1.7796e-04  eta: 3:59:55  time: 1.3502  data_time: 0.0109  memory: 6878  loss: 6.1494  loss_cls: 6.1494
2023/11/30 14:04:29 - mmengine - INFO - Epoch(train)  [1][300/532]  base_lr: 1.8698e-04 lr: 1.8698e-04  eta: 3:55:51  time: 1.3493  data_time: 0.0108  memory: 6878  loss: 6.1197  loss_cls: 6.1197
2023/11/30 14:06:44 - mmengine - INFO - Epoch(train)  [1][400/532]  base_lr: 1.9600e-04 lr: 1.9600e-04  eta: 3:52:43  time: 1.3477  data_time: 0.0108  memory: 6878  loss: 6.1443  loss_cls: 6.1443
2023/11/30 14:08:59 - mmengine - INFO - Epoch(train)  [1][500/532]  base_lr: 2.0503e-04 lr: 2.0503e-04  eta: 3:49:59  time: 1.3519  data_time: 0.0108  memory: 6878  loss: 6.1011  loss_cls: 6.1011
2023/11/30 14:09:41 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:09:41 - mmengine - INFO - Epoch(train)  [1][532/532]  base_lr: 2.0791e-04 lr: 2.0791e-04  eta: 3:48:53  time: 1.3107  data_time: 0.0106  memory: 6878  loss: 6.0616  loss_cls: 6.0616
2023/11/30 14:09:41 - mmengine - INFO - Saving checkpoint at 1 epochs
2023/11/30 14:12:07 - mmengine - INFO - Epoch(train)  [2][100/532]  base_lr: 2.1694e-04 lr: 2.1694e-04  eta: 3:46:24  time: 1.3492  data_time: 0.0110  memory: 6878  loss: 5.9928  loss_cls: 5.9928
2023/11/30 14:14:22 - mmengine - INFO - Epoch(train)  [2][200/532]  base_lr: 2.2596e-04 lr: 2.2596e-04  eta: 3:44:01  time: 1.3484  data_time: 0.0111  memory: 6878  loss: 6.1147  loss_cls: 6.1147
2023/11/30 14:16:37 - mmengine - INFO - Epoch(train)  [2][300/532]  base_lr: 2.3498e-04 lr: 2.3498e-04  eta: 3:41:38  time: 1.3502  data_time: 0.0110  memory: 6878  loss: 6.1175  loss_cls: 6.1175
2023/11/30 14:18:52 - mmengine - INFO - Epoch(train)  [2][400/532]  base_lr: 2.4401e-04 lr: 2.4401e-04  eta: 3:39:17  time: 1.3497  data_time: 0.0111  memory: 6878  loss: 6.1473  loss_cls: 6.1473
2023/11/30 14:20:24 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:21:07 - mmengine - INFO - Epoch(train)  [2][500/532]  base_lr: 2.5303e-04 lr: 2.5303e-04  eta: 3:36:56  time: 1.3478  data_time: 0.0109  memory: 6878  loss: 6.0509  loss_cls: 6.0509
2023/11/30 14:21:49 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:21:49 - mmengine - INFO - Epoch(train)  [2][532/532]  base_lr: 2.5592e-04 lr: 2.5592e-04  eta: 3:36:03  time: 1.3067  data_time: 0.0106  memory: 6878  loss: 6.0347  loss_cls: 6.0347
2023/11/30 14:21:49 - mmengine - INFO - Saving checkpoint at 2 epochs
2023/11/30 14:24:14 - mmengine - INFO - Epoch(train)  [3][100/532]  base_lr: 2.6494e-04 lr: 2.6494e-04  eta: 3:33:44  time: 1.3491  data_time: 0.0109  memory: 6878  loss: 6.1146  loss_cls: 6.1146
2023/11/30 14:26:29 - mmengine - INFO - Epoch(train)  [3][200/532]  base_lr: 2.7396e-04 lr: 2.7396e-04  eta: 3:31:25  time: 1.3450  data_time: 0.0109  memory: 6878  loss: 5.9049  loss_cls: 5.9049
2023/11/30 14:28:43 - mmengine - INFO - Epoch(train)  [3][300/532]  base_lr: 2.8299e-04 lr: 2.8299e-04  eta: 3:29:05  time: 1.3453  data_time: 0.0107  memory: 6878  loss: 6.0827  loss_cls: 6.0827
2023/11/30 14:30:58 - mmengine - INFO - Epoch(train)  [3][400/532]  base_lr: 2.9201e-04 lr: 2.9201e-04  eta: 3:26:45  time: 1.3441  data_time: 0.0109  memory: 6878  loss: 6.0853  loss_cls: 6.0853
2023/11/30 14:33:13 - mmengine - INFO - Epoch(train)  [3][500/532]  base_lr: 3.0103e-04 lr: 3.0103e-04  eta: 3:24:27  time: 1.3511  data_time: 0.0109  memory: 6878  loss: 6.0627  loss_cls: 6.0627
2023/11/30 14:33:55 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:33:55 - mmengine - INFO - Epoch(train)  [3][532/532]  base_lr: 3.0392e-04 lr: 3.0392e-04  eta: 3:23:39  time: 1.3076  data_time: 0.0106  memory: 6878  loss: 6.0845  loss_cls: 6.0845
2023/11/30 14:33:55 - mmengine - INFO - Saving checkpoint at 3 epochs
2023/11/30 14:34:26 - mmengine - INFO - Epoch(val)  [3][100/166]    eta: 0:00:15  time: 0.1867  data_time: 0.0113  memory: 1848  
2023/11/30 14:35:24 - mmengine - INFO - Epoch(val) [3][166/166]    acc/top1: 0.0072  acc/top5: 0.0369  acc/mean1: 0.0064  data_time: 0.0551  time: 0.1933
2023/11/30 14:35:29 - mmengine - INFO - The best checkpoint with 0.0072 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.
2023/11/30 14:37:51 - mmengine - INFO - Epoch(train)  [4][100/532]  base_lr: 3.1294e-04 lr: 3.1294e-04  eta: 3:21:21  time: 1.3478  data_time: 0.0107  memory: 6878  loss: 6.0169  loss_cls: 6.0169
2023/11/30 14:40:06 - mmengine - INFO - Epoch(train)  [4][200/532]  base_lr: 3.2197e-04 lr: 3.2197e-04  eta: 3:19:04  time: 1.3462  data_time: 0.0104  memory: 6878  loss: 5.9685  loss_cls: 5.9685
2023/11/30 14:42:21 - mmengine - INFO - Epoch(train)  [4][300/532]  base_lr: 3.3099e-04 lr: 3.3099e-04  eta: 3:16:48  time: 1.3503  data_time: 0.0110  memory: 6878  loss: 5.9855  loss_cls: 5.9855
2023/11/30 14:44:35 - mmengine - INFO - Epoch(train)  [4][400/532]  base_lr: 3.4001e-04 lr: 3.4001e-04  eta: 3:14:32  time: 1.3470  data_time: 0.0105  memory: 6878  loss: 5.9450  loss_cls: 5.9450
2023/11/30 14:44:41 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:46:50 - mmengine - INFO - Epoch(train)  [4][500/532]  base_lr: 3.4903e-04 lr: 3.4903e-04  eta: 3:12:16  time: 1.3503  data_time: 0.0103  memory: 6878  loss: 5.9318  loss_cls: 5.9318
2023/11/30 14:47:32 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:47:32 - mmengine - INFO - Epoch(train)  [4][532/532]  base_lr: 3.5192e-04 lr: 3.5192e-04  eta: 3:11:29  time: 1.3060  data_time: 0.0104  memory: 6878  loss: 5.9618  loss_cls: 5.9618
2023/11/30 14:47:32 - mmengine - INFO - Saving checkpoint at 4 epochs
2023/11/30 14:49:57 - mmengine - INFO - Epoch(train)  [5][100/532]  base_lr: 3.6094e-04 lr: 3.6094e-04  eta: 3:09:14  time: 1.3470  data_time: 0.0110  memory: 6878  loss: 6.0254  loss_cls: 6.0254
2023/11/30 14:52:12 - mmengine - INFO - Epoch(train)  [5][200/532]  base_lr: 3.6997e-04 lr: 3.6997e-04  eta: 3:06:58  time: 1.3479  data_time: 0.0108  memory: 6878  loss: 6.0209  loss_cls: 6.0209
2023/11/30 14:54:27 - mmengine - INFO - Epoch(train)  [5][300/532]  base_lr: 3.7899e-04 lr: 3.7899e-04  eta: 3:04:42  time: 1.3428  data_time: 0.0109  memory: 6878  loss: 5.9197  loss_cls: 5.9197
2023/11/30 14:56:41 - mmengine - INFO - Epoch(train)  [5][400/532]  base_lr: 3.8801e-04 lr: 3.8801e-04  eta: 3:02:26  time: 1.3466  data_time: 0.0107  memory: 6878  loss: 5.9233  loss_cls: 5.9233
2023/11/30 14:58:56 - mmengine - INFO - Epoch(train)  [5][500/532]  base_lr: 3.9704e-04 lr: 3.9704e-04  eta: 3:00:10  time: 1.3431  data_time: 0.0114  memory: 6878  loss: 5.8841  loss_cls: 5.8841
2023/11/30 14:59:38 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 14:59:38 - mmengine - INFO - Epoch(train)  [5][532/532]  base_lr: 3.9992e-04 lr: 3.9992e-04  eta: 2:59:25  time: 1.3085  data_time: 0.0108  memory: 6878  loss: 5.9262  loss_cls: 5.9262
2023/11/30 14:59:38 - mmengine - INFO - Saving checkpoint at 5 epochs
2023/11/30 15:02:03 - mmengine - INFO - Epoch(train)  [6][100/532]  base_lr: 4.0895e-04 lr: 4.0895e-04  eta: 2:57:10  time: 1.3500  data_time: 0.0111  memory: 6878  loss: 5.9273  loss_cls: 5.9273
2023/11/30 15:04:18 - mmengine - INFO - Epoch(train)  [6][200/532]  base_lr: 4.1797e-04 lr: 4.1797e-04  eta: 2:54:54  time: 1.3509  data_time: 0.0114  memory: 6878  loss: 5.9418  loss_cls: 5.9418
2023/11/30 15:06:33 - mmengine - INFO - Epoch(train)  [6][300/532]  base_lr: 4.2699e-04 lr: 4.2699e-04  eta: 2:52:39  time: 1.3478  data_time: 0.0114  memory: 6878  loss: 5.9204  loss_cls: 5.9204
2023/11/30 15:07:27 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:08:47 - mmengine - INFO - Epoch(train)  [6][400/532]  base_lr: 4.3602e-04 lr: 4.3602e-04  eta: 2:50:23  time: 1.3431  data_time: 0.0115  memory: 6878  loss: 5.9336  loss_cls: 5.9336
2023/11/30 15:11:02 - mmengine - INFO - Epoch(train)  [6][500/532]  base_lr: 4.4504e-04 lr: 4.4504e-04  eta: 2:48:08  time: 1.3450  data_time: 0.0110  memory: 6878  loss: 6.0296  loss_cls: 6.0296
2023/11/30 15:11:44 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:11:44 - mmengine - INFO - Epoch(train)  [6][532/532]  base_lr: 4.4793e-04 lr: 4.4793e-04  eta: 2:47:23  time: 1.3072  data_time: 0.0107  memory: 6878  loss: 5.9388  loss_cls: 5.9388
2023/11/30 15:11:44 - mmengine - INFO - Saving checkpoint at 6 epochs
2023/11/30 15:12:09 - mmengine - INFO - Epoch(val)  [6][100/166]    eta: 0:00:10  time: 0.1494  data_time: 0.0103  memory: 1848  
2023/11/30 15:13:10 - mmengine - INFO - Epoch(val) [6][166/166]    acc/top1: 0.0075  acc/top5: 0.0410  acc/mean1: 0.0067  data_time: 0.0110  time: 0.1462
2023/11/30 15:13:10 - mmengine - INFO - The previous best checkpoint /home/c/caiodasilva/mmaction2/work_dirs/something_knuv_100/best_acc_top1_epoch_3.pth is removed
2023/11/30 15:13:16 - mmengine - INFO - The best checkpoint with 0.0075 acc/top1 at 6 epoch is saved to best_acc_top1_epoch_6.pth.
2023/11/30 15:15:38 - mmengine - INFO - Epoch(train)  [7][100/532]  base_lr: 4.5695e-04 lr: 4.5695e-04  eta: 2:45:07  time: 1.3456  data_time: 0.0113  memory: 6878  loss: 5.9505  loss_cls: 5.9505
2023/11/30 15:17:52 - mmengine - INFO - Epoch(train)  [7][200/532]  base_lr: 4.6597e-04 lr: 4.6597e-04  eta: 2:42:52  time: 1.3429  data_time: 0.0120  memory: 6878  loss: 5.9366  loss_cls: 5.9366
2023/11/30 15:20:07 - mmengine - INFO - Epoch(train)  [7][300/532]  base_lr: 4.7500e-04 lr: 4.7500e-04  eta: 2:40:36  time: 1.3458  data_time: 0.0113  memory: 6878  loss: 5.8392  loss_cls: 5.8392
2023/11/30 15:22:21 - mmengine - INFO - Epoch(train)  [7][400/532]  base_lr: 4.8402e-04 lr: 4.8402e-04  eta: 2:38:21  time: 1.3439  data_time: 0.0114  memory: 6878  loss: 5.9208  loss_cls: 5.9208
2023/11/30 15:24:36 - mmengine - INFO - Epoch(train)  [7][500/532]  base_lr: 4.9304e-04 lr: 4.9304e-04  eta: 2:36:06  time: 1.3450  data_time: 0.0111  memory: 6878  loss: 5.8309  loss_cls: 5.8309
2023/11/30 15:25:18 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:25:18 - mmengine - INFO - Epoch(train)  [7][532/532]  base_lr: 4.9593e-04 lr: 4.9593e-04  eta: 2:35:21  time: 1.3053  data_time: 0.0108  memory: 6878  loss: 5.9118  loss_cls: 5.9118
2023/11/30 15:25:18 - mmengine - INFO - Saving checkpoint at 7 epochs
2023/11/30 15:27:43 - mmengine - INFO - Epoch(train)  [8][100/532]  base_lr: 5.0495e-04 lr: 5.0495e-04  eta: 2:33:07  time: 1.3501  data_time: 0.0114  memory: 6878  loss: 5.9809  loss_cls: 5.9809
2023/11/30 15:29:58 - mmengine - INFO - Epoch(train)  [8][200/532]  base_lr: 5.1398e-04 lr: 5.1398e-04  eta: 2:30:52  time: 1.3475  data_time: 0.0111  memory: 6878  loss: 5.8957  loss_cls: 5.8957
2023/11/30 15:31:40 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:32:12 - mmengine - INFO - Epoch(train)  [8][300/532]  base_lr: 5.2300e-04 lr: 5.2300e-04  eta: 2:28:36  time: 1.3456  data_time: 0.0112  memory: 6878  loss: 5.9199  loss_cls: 5.9199
2023/11/30 15:34:27 - mmengine - INFO - Epoch(train)  [8][400/532]  base_lr: 5.3202e-04 lr: 5.3202e-04  eta: 2:26:21  time: 1.3409  data_time: 0.0109  memory: 6878  loss: 5.8706  loss_cls: 5.8706
2023/11/30 15:36:41 - mmengine - INFO - Epoch(train)  [8][500/532]  base_lr: 5.4105e-04 lr: 5.4105e-04  eta: 2:24:05  time: 1.3437  data_time: 0.0111  memory: 6878  loss: 5.8984  loss_cls: 5.8984
2023/11/30 15:37:23 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:37:23 - mmengine - INFO - Epoch(train)  [8][532/532]  base_lr: 5.4393e-04 lr: 5.4393e-04  eta: 2:23:21  time: 1.3071  data_time: 0.0112  memory: 6878  loss: 5.8632  loss_cls: 5.8632
2023/11/30 15:37:23 - mmengine - INFO - Saving checkpoint at 8 epochs
2023/11/30 15:39:48 - mmengine - INFO - Epoch(train)  [9][100/532]  base_lr: 5.5296e-04 lr: 5.5296e-04  eta: 2:21:06  time: 1.3397  data_time: 0.0109  memory: 6878  loss: 5.8412  loss_cls: 5.8412
2023/11/30 15:42:02 - mmengine - INFO - Epoch(train)  [9][200/532]  base_lr: 5.6198e-04 lr: 5.6198e-04  eta: 2:18:51  time: 1.3460  data_time: 0.0115  memory: 6878  loss: 5.8815  loss_cls: 5.8815
2023/11/30 15:44:17 - mmengine - INFO - Epoch(train)  [9][300/532]  base_lr: 5.7100e-04 lr: 5.7100e-04  eta: 2:16:35  time: 1.3435  data_time: 0.0110  memory: 6878  loss: 5.9624  loss_cls: 5.9624
2023/11/30 15:46:31 - mmengine - INFO - Epoch(train)  [9][400/532]  base_lr: 5.8003e-04 lr: 5.8003e-04  eta: 2:14:20  time: 1.3389  data_time: 0.0110  memory: 6878  loss: 5.8490  loss_cls: 5.8490
2023/11/30 15:48:46 - mmengine - INFO - Epoch(train)  [9][500/532]  base_lr: 5.8905e-04 lr: 5.8905e-04  eta: 2:12:05  time: 1.3453  data_time: 0.0113  memory: 6878  loss: 5.8354  loss_cls: 5.8354
2023/11/30 15:49:28 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:49:28 - mmengine - INFO - Epoch(train)  [9][532/532]  base_lr: 5.9194e-04 lr: 5.9194e-04  eta: 2:11:21  time: 1.3093  data_time: 0.0110  memory: 6878  loss: 5.8252  loss_cls: 5.8252
2023/11/30 15:49:28 - mmengine - INFO - Saving checkpoint at 9 epochs
2023/11/30 15:49:52 - mmengine - INFO - Epoch(val)  [9][100/166]    eta: 0:00:10  time: 0.1484  data_time: 0.0085  memory: 1848  
2023/11/30 15:50:53 - mmengine - INFO - Epoch(val) [9][166/166]    acc/top1: 0.0079  acc/top5: 0.0388  acc/mean1: 0.0070  data_time: 0.0106  time: 0.1449
2023/11/30 15:50:53 - mmengine - INFO - The previous best checkpoint /home/c/caiodasilva/mmaction2/work_dirs/something_knuv_100/best_acc_top1_epoch_6.pth is removed
2023/11/30 15:50:58 - mmengine - INFO - The best checkpoint with 0.0079 acc/top1 at 9 epoch is saved to best_acc_top1_epoch_9.pth.
2023/11/30 15:53:20 - mmengine - INFO - Epoch(train) [10][100/532]  base_lr: 6.0096e-04 lr: 6.0096e-04  eta: 2:09:06  time: 1.3426  data_time: 0.0111  memory: 6878  loss: 5.8590  loss_cls: 5.8590
2023/11/30 15:55:35 - mmengine - INFO - Epoch(train) [10][200/532]  base_lr: 6.0998e-04 lr: 6.0998e-04  eta: 2:06:51  time: 1.3423  data_time: 0.0114  memory: 6878  loss: 5.8919  loss_cls: 5.8919
2023/11/30 15:55:51 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 15:57:49 - mmengine - INFO - Epoch(train) [10][300/532]  base_lr: 6.1901e-04 lr: 6.1901e-04  eta: 2:04:36  time: 1.3405  data_time: 0.0114  memory: 6878  loss: 5.9135  loss_cls: 5.9135
2023/11/30 16:00:03 - mmengine - INFO - Epoch(train) [10][400/532]  base_lr: 6.2803e-04 lr: 6.2803e-04  eta: 2:02:20  time: 1.3384  data_time: 0.0118  memory: 6878  loss: 5.9247  loss_cls: 5.9247
2023/11/30 16:02:17 - mmengine - INFO - Epoch(train) [10][500/532]  base_lr: 6.3705e-04 lr: 6.3705e-04  eta: 2:00:05  time: 1.3415  data_time: 0.0113  memory: 6878  loss: 5.8444  loss_cls: 5.8444
2023/11/30 16:02:59 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:02:59 - mmengine - INFO - Epoch(train) [10][532/532]  base_lr: 6.3994e-04 lr: 6.3994e-04  eta: 1:59:21  time: 1.2967  data_time: 0.0108  memory: 6878  loss: 5.8335  loss_cls: 5.8335
2023/11/30 16:02:59 - mmengine - INFO - Saving checkpoint at 10 epochs
2023/11/30 16:05:23 - mmengine - INFO - Epoch(train) [11][100/532]  base_lr: 6.4896e-04 lr: 6.4896e-04  eta: 1:57:06  time: 1.3392  data_time: 0.0111  memory: 6878  loss: 5.8519  loss_cls: 5.8519
2023/11/30 16:07:37 - mmengine - INFO - Epoch(train) [11][200/532]  base_lr: 6.5799e-04 lr: 6.5799e-04  eta: 1:54:50  time: 1.3367  data_time: 0.0108  memory: 6878  loss: 5.8342  loss_cls: 5.8342
2023/11/30 16:09:51 - mmengine - INFO - Epoch(train) [11][300/532]  base_lr: 6.6701e-04 lr: 6.6701e-04  eta: 1:52:35  time: 1.3385  data_time: 0.0108  memory: 6878  loss: 5.9393  loss_cls: 5.9393
2023/11/30 16:12:05 - mmengine - INFO - Epoch(train) [11][400/532]  base_lr: 6.7603e-04 lr: 6.7603e-04  eta: 1:50:20  time: 1.3386  data_time: 0.0107  memory: 6878  loss: 5.8447  loss_cls: 5.8447
2023/11/30 16:14:18 - mmengine - INFO - Epoch(train) [11][500/532]  base_lr: 6.8506e-04 lr: 6.8506e-04  eta: 1:48:05  time: 1.3371  data_time: 0.0107  memory: 6878  loss: 5.8702  loss_cls: 5.8702
2023/11/30 16:15:00 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:15:00 - mmengine - INFO - Epoch(train) [11][532/532]  base_lr: 6.8794e-04 lr: 6.8794e-04  eta: 1:47:21  time: 1.2978  data_time: 0.0102  memory: 6878  loss: 5.9325  loss_cls: 5.9325
2023/11/30 16:15:00 - mmengine - INFO - Saving checkpoint at 11 epochs
2023/11/30 16:17:24 - mmengine - INFO - Epoch(train) [12][100/532]  base_lr: 6.9697e-04 lr: 6.9697e-04  eta: 1:45:06  time: 1.3382  data_time: 0.0106  memory: 6878  loss: 5.8390  loss_cls: 5.8390
2023/11/30 16:18:29 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:19:38 - mmengine - INFO - Epoch(train) [12][200/532]  base_lr: 7.0599e-04 lr: 7.0599e-04  eta: 1:42:51  time: 1.3367  data_time: 0.0109  memory: 6878  loss: 5.8809  loss_cls: 5.8809
2023/11/30 16:21:52 - mmengine - INFO - Epoch(train) [12][300/532]  base_lr: 7.1501e-04 lr: 7.1501e-04  eta: 1:40:36  time: 1.3433  data_time: 0.0107  memory: 6878  loss: 5.9814  loss_cls: 5.9814
2023/11/30 16:24:06 - mmengine - INFO - Epoch(train) [12][400/532]  base_lr: 7.2404e-04 lr: 7.2404e-04  eta: 1:38:21  time: 1.3366  data_time: 0.0108  memory: 6878  loss: 5.8736  loss_cls: 5.8736
2023/11/30 16:26:20 - mmengine - INFO - Epoch(train) [12][500/532]  base_lr: 7.3306e-04 lr: 7.3306e-04  eta: 1:36:06  time: 1.3401  data_time: 0.0111  memory: 6878  loss: 5.9073  loss_cls: 5.9073
2023/11/30 16:27:02 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:27:02 - mmengine - INFO - Epoch(train) [12][532/532]  base_lr: 7.3595e-04 lr: 7.3595e-04  eta: 1:35:22  time: 1.2966  data_time: 0.0100  memory: 6878  loss: 5.9168  loss_cls: 5.9168
2023/11/30 16:27:02 - mmengine - INFO - Saving checkpoint at 12 epochs
2023/11/30 16:27:26 - mmengine - INFO - Epoch(val) [12][100/166]    eta: 0:00:10  time: 0.1361  data_time: 0.0079  memory: 1848  
2023/11/30 16:28:27 - mmengine - INFO - Epoch(val) [12][166/166]    acc/top1: 0.0075  acc/top5: 0.0377  acc/mean1: 0.0067  data_time: 0.0112  time: 0.1433
2023/11/30 16:30:44 - mmengine - INFO - Epoch(train) [13][100/532]  base_lr: 7.4497e-04 lr: 7.4497e-04  eta: 1:33:09  time: 1.3387  data_time: 0.0105  memory: 6878  loss: 5.9401  loss_cls: 5.9401
2023/11/30 16:32:58 - mmengine - INFO - Epoch(train) [13][200/532]  base_lr: 7.5399e-04 lr: 7.5399e-04  eta: 1:30:54  time: 1.3398  data_time: 0.0104  memory: 6878  loss: 5.8241  loss_cls: 5.8241
2023/11/30 16:35:12 - mmengine - INFO - Epoch(train) [13][300/532]  base_lr: 7.6302e-04 lr: 7.6302e-04  eta: 1:28:39  time: 1.3409  data_time: 0.0105  memory: 6878  loss: 5.8862  loss_cls: 5.8862
2023/11/30 16:37:26 - mmengine - INFO - Epoch(train) [13][400/532]  base_lr: 7.7204e-04 lr: 7.7204e-04  eta: 1:26:25  time: 1.3376  data_time: 0.0106  memory: 6878  loss: 5.8893  loss_cls: 5.8893
2023/11/30 16:39:40 - mmengine - INFO - Epoch(train) [13][500/532]  base_lr: 7.8106e-04 lr: 7.8106e-04  eta: 1:24:10  time: 1.3396  data_time: 0.0108  memory: 6878  loss: 5.8873  loss_cls: 5.8873
2023/11/30 16:40:22 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:40:22 - mmengine - INFO - Epoch(train) [13][532/532]  base_lr: 7.8395e-04 lr: 7.8395e-04  eta: 1:23:26  time: 1.2979  data_time: 0.0109  memory: 6878  loss: 5.8545  loss_cls: 5.8545
2023/11/30 16:40:22 - mmengine - INFO - Saving checkpoint at 13 epochs
2023/11/30 16:42:25 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:42:46 - mmengine - INFO - Epoch(train) [14][100/532]  base_lr: 7.9297e-04 lr: 7.9297e-04  eta: 1:21:11  time: 1.3361  data_time: 0.0106  memory: 6878  loss: 5.8857  loss_cls: 5.8857
2023/11/30 16:45:00 - mmengine - INFO - Epoch(train) [14][200/532]  base_lr: 8.0200e-04 lr: 8.0200e-04  eta: 1:18:57  time: 1.3407  data_time: 0.0104  memory: 6878  loss: 5.8698  loss_cls: 5.8698
2023/11/30 16:47:14 - mmengine - INFO - Epoch(train) [14][300/532]  base_lr: 8.1102e-04 lr: 8.1102e-04  eta: 1:16:42  time: 1.3412  data_time: 0.0104  memory: 6878  loss: 5.9318  loss_cls: 5.9318
2023/11/30 16:49:28 - mmengine - INFO - Epoch(train) [14][400/532]  base_lr: 8.2004e-04 lr: 8.2004e-04  eta: 1:14:27  time: 1.3442  data_time: 0.0110  memory: 6878  loss: 5.8792  loss_cls: 5.8792
2023/11/30 16:51:42 - mmengine - INFO - Epoch(train) [14][500/532]  base_lr: 8.2906e-04 lr: 8.2906e-04  eta: 1:12:13  time: 1.3381  data_time: 0.0108  memory: 6878  loss: 5.8969  loss_cls: 5.8969
2023/11/30 16:52:24 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 16:52:24 - mmengine - INFO - Epoch(train) [14][532/532]  base_lr: 8.3195e-04 lr: 8.3195e-04  eta: 1:11:29  time: 1.2993  data_time: 0.0101  memory: 6878  loss: 5.8791  loss_cls: 5.8791
2023/11/30 16:52:24 - mmengine - INFO - Saving checkpoint at 14 epochs
2023/11/30 16:54:48 - mmengine - INFO - Epoch(train) [15][100/532]  base_lr: 8.4097e-04 lr: 8.4097e-04  eta: 1:09:15  time: 1.3439  data_time: 0.0106  memory: 6878  loss: 5.8855  loss_cls: 5.8855
2023/11/30 16:57:02 - mmengine - INFO - Epoch(train) [15][200/532]  base_lr: 8.5000e-04 lr: 8.5000e-04  eta: 1:07:00  time: 1.3355  data_time: 0.0107  memory: 6878  loss: 5.9060  loss_cls: 5.9060
2023/11/30 16:59:16 - mmengine - INFO - Epoch(train) [15][300/532]  base_lr: 8.5902e-04 lr: 8.5902e-04  eta: 1:04:46  time: 1.3405  data_time: 0.0106  memory: 6878  loss: 5.7972  loss_cls: 5.7972
2023/11/30 17:01:30 - mmengine - INFO - Epoch(train) [15][400/532]  base_lr: 8.6804e-04 lr: 8.6804e-04  eta: 1:02:31  time: 1.3377  data_time: 0.0103  memory: 6878  loss: 5.9303  loss_cls: 5.9303
2023/11/30 17:03:44 - mmengine - INFO - Epoch(train) [15][500/532]  base_lr: 8.7707e-04 lr: 8.7707e-04  eta: 1:00:17  time: 1.3407  data_time: 0.0106  memory: 6878  loss: 5.9029  loss_cls: 5.9029
2023/11/30 17:04:26 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:04:26 - mmengine - INFO - Epoch(train) [15][532/532]  base_lr: 8.7995e-04 lr: 8.7995e-04  eta: 0:59:33  time: 1.2999  data_time: 0.0099  memory: 6878  loss: 5.8720  loss_cls: 5.8720
2023/11/30 17:04:26 - mmengine - INFO - Saving checkpoint at 15 epochs
2023/11/30 17:04:51 - mmengine - INFO - Epoch(val) [15][100/166]    eta: 0:00:10  time: 0.1395  data_time: 0.0077  memory: 1848  
2023/11/30 17:05:53 - mmengine - INFO - Epoch(val) [15][166/166]    acc/top1: 0.0075  acc/top5: 0.0377  acc/mean1: 0.0067  data_time: 0.0122  time: 0.1446
2023/11/30 17:06:23 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:08:10 - mmengine - INFO - Epoch(train) [16][100/532]  base_lr: 8.8898e-04 lr: 8.8898e-04  eta: 0:57:20  time: 1.3402  data_time: 0.0105  memory: 6878  loss: 5.8376  loss_cls: 5.8376
2023/11/30 17:10:24 - mmengine - INFO - Epoch(train) [16][200/532]  base_lr: 8.9800e-04 lr: 8.9800e-04  eta: 0:55:05  time: 1.3360  data_time: 0.0104  memory: 6878  loss: 5.9390  loss_cls: 5.9390
2023/11/30 17:12:38 - mmengine - INFO - Epoch(train) [16][300/532]  base_lr: 9.0702e-04 lr: 9.0702e-04  eta: 0:52:51  time: 1.3371  data_time: 0.0107  memory: 6878  loss: 5.8654  loss_cls: 5.8654
2023/11/30 17:14:52 - mmengine - INFO - Epoch(train) [16][400/532]  base_lr: 9.1605e-04 lr: 9.1605e-04  eta: 0:50:36  time: 1.3421  data_time: 0.0103  memory: 6878  loss: 5.8624  loss_cls: 5.8624
2023/11/30 17:17:06 - mmengine - INFO - Epoch(train) [16][500/532]  base_lr: 9.2507e-04 lr: 9.2507e-04  eta: 0:48:22  time: 1.3411  data_time: 0.0105  memory: 6878  loss: 5.8256  loss_cls: 5.8256
2023/11/30 17:17:48 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:17:48 - mmengine - INFO - Epoch(train) [16][532/532]  base_lr: 9.2796e-04 lr: 9.2796e-04  eta: 0:47:39  time: 1.2994  data_time: 0.0101  memory: 6878  loss: 5.8849  loss_cls: 5.8849
2023/11/30 17:17:48 - mmengine - INFO - Saving checkpoint at 16 epochs
2023/11/30 17:20:12 - mmengine - INFO - Epoch(train) [17][100/532]  base_lr: 9.3698e-04 lr: 9.3698e-04  eta: 0:45:24  time: 1.3375  data_time: 0.0105  memory: 6878  loss: 5.7986  loss_cls: 5.7986
2023/11/30 17:22:26 - mmengine - INFO - Epoch(train) [17][200/532]  base_lr: 9.4600e-04 lr: 9.4600e-04  eta: 0:43:10  time: 1.3330  data_time: 0.0105  memory: 6878  loss: 5.8412  loss_cls: 5.8412
2023/11/30 17:24:40 - mmengine - INFO - Epoch(train) [17][300/532]  base_lr: 9.5503e-04 lr: 9.5503e-04  eta: 0:40:55  time: 1.3417  data_time: 0.0105  memory: 6878  loss: 5.8862  loss_cls: 5.8862
2023/11/30 17:26:54 - mmengine - INFO - Epoch(train) [17][400/532]  base_lr: 9.6405e-04 lr: 9.6405e-04  eta: 0:38:41  time: 1.3426  data_time: 0.0107  memory: 6878  loss: 5.8675  loss_cls: 5.8675
2023/11/30 17:28:52 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:29:08 - mmengine - INFO - Epoch(train) [17][500/532]  base_lr: 9.7307e-04 lr: 9.7307e-04  eta: 0:36:27  time: 1.3383  data_time: 0.0108  memory: 6878  loss: 5.8913  loss_cls: 5.8913
2023/11/30 17:29:50 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:29:50 - mmengine - INFO - Epoch(train) [17][532/532]  base_lr: 9.7596e-04 lr: 9.7596e-04  eta: 0:35:43  time: 1.2973  data_time: 0.0100  memory: 6878  loss: 5.9496  loss_cls: 5.9496
2023/11/30 17:29:50 - mmengine - INFO - Saving checkpoint at 17 epochs
2023/11/30 17:32:14 - mmengine - INFO - Epoch(train) [18][100/532]  base_lr: 9.8498e-04 lr: 9.8498e-04  eta: 0:33:29  time: 1.3361  data_time: 0.0105  memory: 6878  loss: 5.8506  loss_cls: 5.8506
2023/11/30 17:34:28 - mmengine - INFO - Epoch(train) [18][200/532]  base_lr: 9.9401e-04 lr: 9.9401e-04  eta: 0:31:15  time: 1.3384  data_time: 0.0106  memory: 6878  loss: 5.8578  loss_cls: 5.8578
2023/11/30 17:36:42 - mmengine - INFO - Epoch(train) [18][300/532]  base_lr: 1.0030e-03 lr: 1.0030e-03  eta: 0:29:00  time: 1.3397  data_time: 0.0105  memory: 6878  loss: 5.8782  loss_cls: 5.8782
2023/11/30 17:38:55 - mmengine - INFO - Epoch(train) [18][400/532]  base_lr: 1.0121e-03 lr: 1.0121e-03  eta: 0:26:46  time: 1.3411  data_time: 0.0105  memory: 6878  loss: 5.8618  loss_cls: 5.8618
2023/11/30 17:41:09 - mmengine - INFO - Epoch(train) [18][500/532]  base_lr: 1.0211e-03 lr: 1.0211e-03  eta: 0:24:31  time: 1.3352  data_time: 0.0106  memory: 6878  loss: 5.8445  loss_cls: 5.8445
2023/11/30 17:41:51 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:41:51 - mmengine - INFO - Epoch(train) [18][532/532]  base_lr: 1.0240e-03 lr: 1.0240e-03  eta: 0:23:48  time: 1.3000  data_time: 0.0102  memory: 6878  loss: 5.8648  loss_cls: 5.8648
2023/11/30 17:41:51 - mmengine - INFO - Saving checkpoint at 18 epochs
2023/11/30 17:42:16 - mmengine - INFO - Epoch(val) [18][100/166]    eta: 0:00:09  time: 0.1431  data_time: 0.0095  memory: 1848  
2023/11/30 17:43:16 - mmengine - INFO - Epoch(val) [18][166/166]    acc/top1: 0.0075  acc/top5: 0.0369  acc/mean1: 0.0067  data_time: 0.0107  time: 0.1423
2023/11/30 17:45:34 - mmengine - INFO - Epoch(train) [19][100/532]  base_lr: 1.0330e-03 lr: 1.0330e-03  eta: 0:21:34  time: 1.3421  data_time: 0.0105  memory: 6878  loss: 5.8865  loss_cls: 5.8865
2023/11/30 17:47:47 - mmengine - INFO - Epoch(train) [19][200/532]  base_lr: 1.0420e-03 lr: 1.0420e-03  eta: 0:19:20  time: 1.3376  data_time: 0.0105  memory: 6878  loss: 5.8653  loss_cls: 5.8653
2023/11/30 17:50:01 - mmengine - INFO - Epoch(train) [19][300/532]  base_lr: 1.0510e-03 lr: 1.0510e-03  eta: 0:17:06  time: 1.3383  data_time: 0.0110  memory: 6878  loss: 5.8132  loss_cls: 5.8132
2023/11/30 17:52:15 - mmengine - INFO - Epoch(train) [19][400/532]  base_lr: 1.0601e-03 lr: 1.0601e-03  eta: 0:14:51  time: 1.3428  data_time: 0.0106  memory: 6878  loss: 5.8435  loss_cls: 5.8435
2023/11/30 17:52:47 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:54:29 - mmengine - INFO - Epoch(train) [19][500/532]  base_lr: 1.0691e-03 lr: 1.0691e-03  eta: 0:12:37  time: 1.3421  data_time: 0.0105  memory: 6878  loss: 5.8878  loss_cls: 5.8878
2023/11/30 17:55:12 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 17:55:12 - mmengine - INFO - Epoch(train) [19][532/532]  base_lr: 1.0720e-03 lr: 1.0720e-03  eta: 0:11:54  time: 1.3119  data_time: 0.0100  memory: 6878  loss: 5.8601  loss_cls: 5.8601
2023/11/30 17:55:12 - mmengine - INFO - Saving checkpoint at 19 epochs
2023/11/30 17:57:36 - mmengine - INFO - Epoch(train) [20][100/532]  base_lr: 1.0810e-03 lr: 1.0810e-03  eta: 0:09:40  time: 1.3324  data_time: 0.0106  memory: 6878  loss: 5.8671  loss_cls: 5.8671
2023/11/30 17:59:50 - mmengine - INFO - Epoch(train) [20][200/532]  base_lr: 1.0900e-03 lr: 1.0900e-03  eta: 0:07:25  time: 1.3413  data_time: 0.0106  memory: 6878  loss: 5.9105  loss_cls: 5.9105
2023/11/30 18:02:04 - mmengine - INFO - Epoch(train) [20][300/532]  base_lr: 1.0990e-03 lr: 1.0990e-03  eta: 0:05:11  time: 1.3377  data_time: 0.0105  memory: 6878  loss: 5.9108  loss_cls: 5.9108
2023/11/30 18:04:18 - mmengine - INFO - Epoch(train) [20][400/532]  base_lr: 1.1081e-03 lr: 1.1081e-03  eta: 0:02:57  time: 1.3391  data_time: 0.0105  memory: 6878  loss: 5.8604  loss_cls: 5.8604
2023/11/30 18:06:32 - mmengine - INFO - Epoch(train) [20][500/532]  base_lr: 1.1171e-03 lr: 1.1171e-03  eta: 0:00:42  time: 1.3363  data_time: 0.0107  memory: 6878  loss: 5.8713  loss_cls: 5.8713
2023/11/30 18:07:14 - mmengine - INFO - Exp name: something_knuv_100_20231130_135729
2023/11/30 18:07:14 - mmengine - INFO - Epoch(train) [20][532/532]  base_lr: 1.1200e-03 lr: 1.1200e-03  eta: 0:00:00  time: 1.2984  data_time: 0.0101  memory: 6878  loss: 5.8553  loss_cls: 5.8553
2023/11/30 18:07:14 - mmengine - INFO - Saving checkpoint at 20 epochs
 